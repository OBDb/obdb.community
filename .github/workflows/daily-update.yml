# .github/workflows/daily-update.yml
name: Daily Data Update

on:
  schedule:
    - cron: '0 5,11,17,23 * * *'
  workflow_dispatch:  # Allows manual triggering

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "data-update"
  cancel-in-progress: false

jobs:
  update-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install jsonschema pyyaml

      - name: Install GitHub CLI
        run: |
          type -p curl >/dev/null || apt install curl -y
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
          && sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
          && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
          && sudo DEBIAN_FRONTEND=noninteractive apt update \
          && sudo DEBIAN_FRONTEND=noninteractive apt install --no-install-recommends gh -y

      - name: Authenticate with GitHub CLI
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | gh auth login --with-token

      - name: Create data directory
        run: |
          mkdir -p public/data

      # Cache the workspace directory containing cloned repositories
      - name: Cache workspace repositories
        id: cache-workspace
        uses: actions/cache@v3
        with:
          path: workspace
          # The cache key depends on the day of month to refresh cache periodically
          # This ensures a fresh clone every month while using cache for daily updates
          key: ${{ runner.os }}-workspace-${{ github.run_id }}-${{ github.run_number }}
          restore-keys: |
            ${{ runner.os }}-workspace-

      - name: Create workspace directory if it doesn't exist
        if: steps.cache-workspace.outputs.cache-hit != 'true'
        run: mkdir -p workspace

      - name: Run data extraction script
        run: |
          python scripts/extract_data.py --fetch --workspace workspace --output public/data
        id: extract_data

      - name: Check for changes in data
        id: check_changes
        run: |
          # Check if the file exists
          if [ ! -f "public/data/matrix_data.json" ]; then
            echo "File does not exist yet, will create it"
            echo "changed=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # First verify that the file is valid JSON
          python -c "import json; json.load(open('public/data/matrix_data.json'))" || {
            echo "Invalid JSON detected, will regenerate"
            echo "changed=true" >> $GITHUB_OUTPUT
            exit 0
          }

          # Check if there are changes to commit
          if git diff --quiet public/data/matrix_data.json public/data/model_years_data.json public/data/generations_data.json; then
            echo "No changes detected in data files"
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected in data files"
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Configure Git
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Commit and push changes
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          # Run validation script one more time to ensure consistent formatting
          python scripts/validate_json.py --input public/data/matrix_data.json --output public/data/matrix_data.json

          # Validate model years data if it exists
          if [ -f public/data/model_years_data.json ]; then
            python scripts/validate_json.py --input public/data/model_years_data.json --output public/data/model_years_data.json
          fi

          # Validate generations data if it exists
          if [ -f public/data/generations_data.json ]; then
            python scripts/validate_json.py --input public/data/generations_data.json --output public/data/generations_data.json
          fi

          git add public/data/matrix_data.json public/data/model_years_data.json public/data/generations_data.json
          git commit -m "Update matrix data from OBDb repositories [skip ci]"
          git push
          echo "commit_sha=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT

  # Build and deployment job - similar to the existing static.yml workflow
  deploy:
    needs: update-data
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main  # Make sure we have the latest changes

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Create data directory for build
        run: mkdir -p public/data

      - name: Generate SAEJ1979 commands data
        run: node scripts/generate_saej1979_commands.js

      - name: Copy CNAME to public folder
        run: cp CNAME public/

      - name: Build React app
        run: npm run build
        env:
          CI: false # This prevents the build from failing on warnings
          PUBLIC_URL: "https://obdb.community"

      - name: Create .nojekyll file
        run: touch build/.nojekyll

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './build'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
